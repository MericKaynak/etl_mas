{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c54093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "import gradio as gr\n",
    "from gradio import ChatMessage\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "\n",
    "from modules.schema_analyzer import SchemaAnalyzer\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "KB_DIR = Path(\"../knowledge_base\")\n",
    "SUPPORTED_EXTS = [\".csv\", \".json\", \".xlsx\", \".xml\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd3c510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def list_kb_files():\n",
    "    return [str(p.name) for p in KB_DIR.glob(\"*\") if p.suffix.lower() in SUPPORTED_EXTS]\n",
    "\n",
    "async def respond(message, chat_history, selected_files, uploaded_files):\n",
    "    selected_paths = [KB_DIR / name for name in selected_files]\n",
    "    uploaded_paths = [Path(f.name) for f in uploaded_files or []]\n",
    "    all_paths = selected_paths + uploaded_paths\n",
    "\n",
    "    combined_content = []\n",
    "\n",
    "    for path in all_paths:\n",
    "        try:\n",
    "            analyzer = SchemaAnalyzer(str(path))\n",
    "            schema_result = analyzer.analyze()\n",
    "            snippets = analyzer.get_file_snippets(n=10)\n",
    "\n",
    "            schema_str = json.dumps(schema_result, indent=2)\n",
    "            head_str = snippets.get(\"head\", \"\")\n",
    "            middle_str = snippets.get(\"middle\", \"\")\n",
    "            tail_str = snippets.get(\"tail\", \"\")\n",
    "\n",
    "            file_block = f\"\"\"\\n=== File: {path.name} ===\\n\n",
    "            ðŸ“Š Schema:\n",
    "            {schema_str}\n",
    "\n",
    "            ðŸ“„ Head:\n",
    "            {head_str}\n",
    "\n",
    "            ðŸ“„ Middle:\n",
    "            {middle_str}\n",
    "\n",
    "            ðŸ“„ Tail:\n",
    "            {tail_str}\n",
    "            \"\"\"\n",
    "            combined_content.append(file_block)\n",
    "\n",
    "        except Exception as e:\n",
    "            combined_content.append(f\"=== File: {path.name} ===\\n Error while parsing: {str(e)}\\n\")\n",
    "\n",
    "    full_data_context = \"\\n\\n\".join(combined_content)\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"Your task is to analyze the uploaded data and infer a relational structure from it. Pay special attention to identifying which classes belong to which documents or are derived from which documents. Then, generate a LinkML schema proposal that captures the structure, relationships between classes, and their association with the respective documents. Format the output as valid LinkML inside a code block.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"User question: {message}\\n\\nHere is the data context:\\n{full_data_context}\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    buffer = \"\"\n",
    "    async for chunk in llm.astream(messages):\n",
    "        if hasattr(chunk, \"content\") and chunk.content:\n",
    "            buffer += chunk.content\n",
    "            yield buffer \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸ§  File-to-LinkML Schema Chatbot\")\n",
    "\n",
    "    with gr.Accordion(\"ðŸ“‚ Select or upload files\", open=False) as inputs_accordion:\n",
    "        kb_files = gr.CheckboxGroup(\n",
    "            label=\"Select files from knowledge_base\",\n",
    "            choices=list_kb_files()\n",
    "        )\n",
    "        uploads = gr.File(\n",
    "            label=\"Upload your own files\",\n",
    "            file_types=SUPPORTED_EXTS,\n",
    "            file_count=\"multiple\"\n",
    "        )\n",
    "\n",
    "    chatbot = gr.ChatInterface(\n",
    "        fn=respond,\n",
    "        title=\"LinkML Schema Generator\",\n",
    "        type=\"messages\",\n",
    "        additional_inputs=[kb_files, uploads],\n",
    "        additional_inputs_accordion=inputs_accordion,\n",
    "        save_history=True,\n",
    "        examples=[[\"Can you design a LinkML schema for the attached data?\"]],\n",
    "    )\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
